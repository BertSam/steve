{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes how to build, train and analyse the neural network for SASE pulses classification. It also contains many useful tool for neural networks in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import os\n",
    "import random as rn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "NB_CHANNELS = 16\n",
    "NB_LABELS = 5\n",
    "n = 3 # (Number of quantization bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_gpu(Flag):\n",
    "# (0 = GPU, -1 = CPU)    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = Flag  \n",
    "    if tf.test.gpu_device_name():\n",
    "        print('GPU found')\n",
    "    else:\n",
    "        print(\"No GPU found\")\n",
    "    return\n",
    "\n",
    "    \n",
    "def doWeights(model):\n",
    "\n",
    "    allWeightsByLayer = {}\n",
    "    for layer in model.layers:\n",
    "        if (layer._name).find(\"batch\")!=-1 or len(layer.get_weights())<1:\n",
    "            continue \n",
    "        weights=layer.weights[0].numpy().flatten()  \n",
    "        allWeightsByLayer[layer._name] = weights\n",
    "        print('Layer {}: % of zeros = {}'.format(layer._name,np.sum(weights==0)/np.size(weights)))\n",
    "\n",
    "    labelsW = []\n",
    "    histosW = []\n",
    "\n",
    "    for key in reversed(sorted(allWeightsByLayer.keys())):\n",
    "        labelsW.append(key)\n",
    "        histosW.append(allWeightsByLayer[key])\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    bins = np.linspace(-1.5, 1.5, 50)\n",
    "    plt.hist(histosW,bins,histtype='stepfilled',stacked=True,label=labelsW, edgecolor='black')\n",
    "    plt.legend(frameon=False,loc='upper left')\n",
    "    plt.ylabel('Number of Weights')\n",
    "    plt.xlabel('Weights')\n",
    "    plt.figtext(0.2, 0.38,model._name, wrap=True, horizontalalignment='left',verticalalignment='center')\n",
    "\n",
    "def get_dense_layer_weights(model):\n",
    "    w = []\n",
    "    b = []\n",
    "    for layer in model.layers:\n",
    "        if (layer._name).find(\"batch\")!=-1 or len(layer.get_weights())<1:\n",
    "            continue \n",
    "        w.append(layer.get_weights()[0])\n",
    "        b.append(layer.get_weights()[1])\n",
    "\n",
    "    return w, b   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed Setup\n",
    "seed_value = 1\n",
    "keras_kernel_initializer = 'lecun_uniform'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# Selecting CPU or GPU     \n",
    "use_gpu('-1')  # ('0' = GPU, '-1' = CPU) (for small fc nn, cpu is faster)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "X_test = np.load('../dataset/test_set_' + str(n) + 'bits_opt.npz')['X_test']\n",
    "Y_test = np.load('../dataset/test_set_' + str(n) + 'bits_opt.npz')['Y_test']\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Activation, Input, Flatten, Dense, ReLU, Softmax\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "input_shape = (NB_CHANNELS,2**n,1)\n",
    "\n",
    "model = Sequential(name='fc')\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4, name='fc1',kernel_initializer='lecun_uniform'))\n",
    "model.add(ReLU(name='relu1', max_value=None, negative_slope=0.0, threshold=0.0))\n",
    "\n",
    "model.add(Dense(32, name='fc2',\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(ReLU(name='relu2', max_value=None, negative_slope=0.0, threshold=0.0))\n",
    "\n",
    "model.add(Dense(32, name='fc3',\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(ReLU(name='relu3', max_value=None, negative_slope=0.0, threshold=0.0))\n",
    "\n",
    "model.add(Dense(NB_LABELS, name='output',\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Softmax(name='output_softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_flag = False\n",
    "\n",
    "if train_flag:\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "    history = model.fit(X_test, Y_test, batch_size=512, epochs=10, validation_split=0.2, shuffle=True)\n",
    "\n",
    "    training_loss = history.history['loss']\n",
    "    training_acc = history.history['accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    model.save(\"../preTrained_models/dev_model.h5\")\n",
    "    np.savez(\"../preTrained_models/history.npz\", training_loss=training_loss, training_acc=training_acc, val_loss=val_loss, val_acc=val_acc)\n",
    "\n",
    "else:\n",
    "    model = load_model(\"../preTrained_models/dev_model.h5\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "    training_loss = np.load(\"../preTrained_models/history.npz\")['training_loss']\n",
    "    training_acc = np.load(\"../preTrained_models/history.npz\")['training_acc']\n",
    "    val_loss = np.load(\"../preTrained_models/history.npz\")['val_loss']\n",
    "    val_acc = np.load(\"../preTrained_models/history.npz\")['val_acc']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_acc,label='training set')\n",
    "plt.plot(val_acc, label='validation set')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting weights. Because there is no weights and bias in activation function, the list indice represent the n'th dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = get_dense_layer_weights(model)\n",
    "\n",
    "print(w[0].shape)    # this is the weights from the first dense layer\n",
    "print(w[1].shape)     # this is the weights from the seconde dense layer\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "\n",
    "print(b[0].shape)    # this is the bias from the first dense layer\n",
    "print(b[1].shape)     # this is the bias from the seconde dense layer\n",
    "# .\n",
    "# .\n",
    "# ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doWeights(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output from intermediate layer. Because the Dense AND the activation function are both consider \"layers\", the list indice represent the n'th layer (including Dense AND the activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = keras.Model(inputs=model.inputs,\n",
    "                        outputs=[layer.output for layer in model.layers])\n",
    "features = extractor(X_test[0:23])   # testing with the 22 first images\n",
    "\n",
    "print('FLATTEN layer output:\\n', features[0][22].numpy())  # this is the output from the FLATTEN layer with the 22nd test image before activator\n",
    "print('FIRST DENSE layer output:\\n', features[1][22].numpy())  # this is the output from the FIRST DENSE layer with the 22nd test image (before activation function)\n",
    "print('FIRST RELU layer output:\\n', features[2][22].numpy())  # this is the output from the FIRST RELU layer with the 22nd test image (after activation function)\n",
    "print('.\\n.\\n.\\n')\n",
    "# .\n",
    "# .\n",
    "# ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell present how to extract specific layer parameter for comparison and network analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights, bias extraction\n",
    "w, b = get_dense_layer_weights(model)\n",
    "\n",
    "# Intermediate output\n",
    "extractor = keras.Model(inputs=model.inputs,\n",
    "                        outputs=[layer.output for layer in model.layers])\n",
    "features = extractor(X_test[0:23])   # testing with the 22 first images\n",
    "\n",
    "\n",
    "print('FIRST DENSE layer output:\\n', features[1][22].numpy())  # this is the output from the FIRST DENSE layer with the 22nd test image (before activation function)\n",
    "print('FIRST RELU layer output:\\n', features[2][22].numpy())  # this is the output from the FIRST RELU layer with the 22nd test image (after activation function)\n",
    "\n",
    "print('FIRST DENSE layer bias:\\n', b[0])  # bias from the FIRST DENSE layer\n",
    "print('FIRST DENSE layer weights:\\n', w[0])  # weights from the FIRST DENSE layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " * MIT License\n",
    " *\n",
    " * Copyright (c) 2022 SLAC National Accelerator Laboratory\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in all\n",
    " * copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    " * SOFTWARE.\n",
    " *\n",
    " * Authors : Berthié Gouin-Ferland\n",
    " * Last update : 2022-12-08\n",
    " *\n",
    " * Description : This notebook describes how to build, train and analyse the neural network for SASE pulses classification. It also contains many useful tool for neural networks in general.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (default, Nov 16 2020, 16:55:22) \n[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
