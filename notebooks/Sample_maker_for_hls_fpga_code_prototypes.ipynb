{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scales the date and generates a sample to test the proto-algo in hls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from multiprocess import Pool\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use('seaborn')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import nonuniform_quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File info (modify according to your environment and dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/sdf/home/b/berthie/tmox42619_data/h5files/hits.tmox42619.run135.h5'\n",
    "good_ports = ['port_0','port_1','port_4','port_5','port_12','port_13','port_14','port_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(file_path, 'r')\n",
    "\n",
    "raw_tofs = []\n",
    "for port in good_ports:\n",
    "    temp = np.asarray(f[port]['tofs'][1:])\n",
    "    raw_tofs.append(temp-temp.min())      # I subtract the minimum value so it shifts the spectrum \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantizer (Choose \"n\", the number of bit for the quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = nonuniform_quantization.quantizer(Nb_bits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantizer Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:26<00:00,  3.33s/it]\n"
     ]
    }
   ],
   "source": [
    "with Pool(16) as p:\n",
    "    pool_outputs = list(\n",
    "        tqdm(\n",
    "            p.imap(Q.training,\n",
    "                   raw_tofs),\n",
    "            total=len(good_ports)\n",
    "        )\n",
    "    ) \n",
    "\n",
    "tofs_QLvl = []\n",
    "for port in range(len(good_ports)):\n",
    "    tofs_QLvl.append(pool_outputs[port][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 259.22it/s]\n"
     ]
    }
   ],
   "source": [
    "quantized_tofs_cluster_assignments = []\n",
    "quantized_tofs = []\n",
    "for port in tqdm(range(len(good_ports))):\n",
    "    quantized_tofs_temp, quantized_tofs_cluster_assignments_temp = Q.quantization(raw_tofs[port], tofs_QLvl[port], return_cluster_assignments=True)\n",
    "    quantized_tofs_cluster_assignments.append(quantized_tofs_cluster_assignments_temp)\n",
    "    quantized_tofs.append(quantized_tofs_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell iteratively find the unity resolution we need to represente all possible TOF values over all the dynamic range as a integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:08<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "assignment_pts_index = []\n",
    "raw_tofs_index = []\n",
    "quantized_tofs_index = []\n",
    "quantized_tofs_index_cluster_assignments = []\n",
    "\n",
    "for port in tqdm(range(len(good_ports))):\n",
    "    all_samples =  raw_tofs[port]\n",
    "    max_value = all_samples.max()\n",
    "\n",
    "    b=1\n",
    "    all_samples_normalized = all_samples/max_value\n",
    "    all_samples_normalized_scaled = np.floor(all_samples_normalized*(2**b)).astype(int)\n",
    "\n",
    "    while(len(np.unique(all_samples)) != len(np.unique(all_samples_normalized_scaled))):\n",
    "        b+=1\n",
    "        all_samples_normalized_scaled = np.floor(all_samples_normalized*(2**b)).astype(int)\n",
    "\n",
    "    raw_tofs_index_temp = all_samples_normalized_scaled\n",
    "\n",
    "    assignment_pts = tofs_QLvl[port]\n",
    "    assignment_pts_normalized = assignment_pts/max_value\n",
    "    assignment_pts_normalized_scaled = np.floor(assignment_pts_normalized*(2**b)).astype(int)\n",
    "    assignment_pts_index_temp = assignment_pts_normalized_scaled\n",
    "\n",
    "    # We can then quantized the same way, but now all values are integer. Note that the cluster assignments are exactly the same as when using the floating values.\n",
    "    quantized_tofs_index_temp, quantized_tofs_index_cluster_assignments_temp = Q.quantization(raw_tofs_index_temp, assignment_pts_index_temp, return_cluster_assignments = True)\n",
    "\n",
    "    assignment_pts_index.append(assignment_pts_index_temp)\n",
    "    raw_tofs_index.append(raw_tofs_index_temp)\n",
    "    quantized_tofs_index.append(quantized_tofs_index_temp)\n",
    "    quantized_tofs_index_cluster_assignments.append(quantized_tofs_index_cluster_assignments_temp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save a sample of data to test the quantizer and the histogram in hls."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaling allows for \"unsingned long\" datatype which aim to lower the ressources usgae on FPGA (note that the quantizer and histogram c code only work as a \"stream\" at the moment. Metadata, such as \"channel, \"adresses\" and \"nedge\" are needed to make the histogram) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hist(x, Q_lvls):\n",
    "    hist_temp = np.zeros_like(Q_lvls)\n",
    "    for i in range(len(x)):\n",
    "        hist_temp[x[i]] += 1\n",
    "    return hist_temp\n",
    "\n",
    "\n",
    "cpp_port_test = 0\n",
    "\n",
    "cpp_q_lvl_ref = assignment_pts_index[cpp_port_test][:].astype(int)\n",
    "cpp_q_samples_ref = quantized_tofs_index_cluster_assignments[cpp_port_test][0:1000].astype(int)\n",
    "cpp_raw_samples = quantized_tofs_index[cpp_port_test][0:1000].astype(int)\n",
    "cpp_hist_ref = my_hist(cpp_q_samples_ref, cpp_q_lvl_ref).astype(int)\n",
    "\n",
    "np.savetxt('../hls_prototypes/c_files/cpp_hist_ref.dat',cpp_hist_ref,fmt=\"%u\")\n",
    "np.savetxt('../hls_prototypes/c_files/q_lvls.dat',cpp_q_lvl_ref,fmt=\"%u\")\n",
    "np.savetxt('../hls_prototypes/c_files/raw.dat',cpp_raw_samples,fmt=\"%u\")\n",
    "np.savetxt('../hls_prototypes/c_files/q_ref.dat',cpp_q_samples_ref,fmt=\"%u\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " * MIT License\n",
    " *\n",
    " * Copyright (c) 2022 SLAC National Accelerator Laboratory\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in all\n",
    " * copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    " * SOFTWARE.\n",
    " *\n",
    " * Authors : Berthié Gouin-Ferland\n",
    " * Last update : 2022-12-06\n",
    " *\n",
    " * Description : This notebook scales the date and generates a sample to test the proto-algo in hls\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (default, Nov 16 2020, 16:55:22) \n[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b80ca9f53774b17246e07599957de40441300c341d9c2731d22ec0982c71606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
